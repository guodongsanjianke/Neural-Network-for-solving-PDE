{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import h5py\n",
    "import sklearn.metrics\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "import torch.nn as nn\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from torch.nn import Parameter\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.inits import reset, uniform\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = 'data/piececonst_r241_N1024_smooth1.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = 'data/piececonst_r241_N1024_smooth2.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatReader(object):\n",
    "    def __init__(self, file_path, to_torch=True, to_cuda=False, to_float=True):\n",
    "        super(MatReader, self).__init__()\n",
    "        \n",
    "        self.to_torch = to_torch\n",
    "        self.to_cuda = to_cuda\n",
    "        self.to_float = to_float\n",
    "        \n",
    "        self.file_path = file_path\n",
    "        \n",
    "        self.data = None\n",
    "        self.old_mat = None\n",
    "        self._load_file()\n",
    "        \n",
    "    def _load_file(self):\n",
    "        try:\n",
    "            self.data = scipy.io.loadmat(self.file_path)\n",
    "            self.old_mat = True\n",
    "        except:\n",
    "            self.data = h5py.File(self.file_path)\n",
    "            self.old_mat = False\n",
    "            \n",
    "    def load_file(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self._load_file()\n",
    "        \n",
    "        if not self.old_mat:\n",
    "            x = x[()]\n",
    "            x = np.transpose(x, axes=range(len(x.shape)- 1, -1, -1))\n",
    "            \n",
    "        if self.to_float:\n",
    "            x = x.astype(np.float32)\n",
    "            \n",
    "        if self.to_torch:\n",
    "            x = torch.from_numpy(x)\n",
    "            \n",
    "            if self.to_cuda:\n",
    "                x = x.cuda()\n",
    "                \n",
    "    def read_field(self, field):\n",
    "        x = self.data[field]\n",
    "        \n",
    "        if not self.old_mat:\n",
    "            x = x[()]\n",
    "            x = np.transpose(x, axes=range(len(x.shape) - 1, -1, -1))\n",
    "            \n",
    "        if self.to_float:\n",
    "            x = x.astype(np.float32)\n",
    "        \n",
    "        if self.to_torch:\n",
    "            x = torch.from_numpy(x)\n",
    "            \n",
    "            if self.to_cuda:\n",
    "                x = x.cuda()\n",
    "                \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_train = MatReader(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = 4\n",
    "ntrain = 100\n",
    "train_a = reader_train.read_field('coeff')[:ntrain,::r,::r].reshape(ntrain,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a_smooth = reader_train.read_field('Kcoeff')[:ntrain,::r,::r].reshape(ntrain,-1)\n",
    "train_a_gradx = reader_train.read_field('Kcoeff_x')[:ntrain,::r,::r].reshape(ntrain,-1)\n",
    "train_a_grady = reader_train.read_field('Kcoeff_y')[:ntrain,::r,::r].reshape(ntrain,-1)\n",
    "train_u = reader_train.read_field('sol')[:ntrain,::r,::r].reshape(ntrain,-1)\n",
    "train_u64 = reader_train.read_field('sol')[:ntrain,::r,::r].reshape(ntrain,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntest = 40\n",
    "reader_test = MatReader(TEST_PATH)\n",
    "test_a = reader_test.read_field('coeff')[:ntest,::r,::r].reshape(ntest,-1)\n",
    "test_a_smooth = reader_test.read_field('Kcoeff')[:ntest,::r,::r].reshape(ntest,-1)\n",
    "test_a_gradx = reader_test.read_field('Kcoeff_x')[:ntest,::r,::r].reshape(ntest,-1)\n",
    "test_a_grady = reader_test.read_field('Kcoeff_y')[:ntest,::r,::r].reshape(ntest,-1)\n",
    "test_u = reader_test.read_field('sol')[:ntest,::r,::r].reshape(ntest,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNormalizer(object):\n",
    "    def __init__(self, x, eps=0.00001):\n",
    "        super(GaussianNormalizer, self).__init__()\n",
    "        \n",
    "        self.mean = torch.mean(x)\n",
    "        self.std = torch.std(x)\n",
    "        self.eps = eps\n",
    "        \n",
    "    def encode(self,x):\n",
    "        x = (x - self.mean) / (self.std + self.eps)\n",
    "        return x\n",
    "    \n",
    "    def cuda(self):\n",
    "        self.mean = self.mean.cuda()\n",
    "        self.std = self.std.cuda()\n",
    "        \n",
    "    def decode(self, x, sample_idx=None):\n",
    "        x = (x *(self.std + self.eps)) + self.mean\n",
    "        \n",
    "    def cup(self):\n",
    "        self.mean = self.mean.cpu()\n",
    "        self.std = self.std.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_normalizer_train = GaussianNormalizer(train_a)\n",
    "a_normalizer_test = GaussianNormalizer(test_a)\n",
    "train_a = a_normalizer_train.encode(train_a)\n",
    "test_a = a_normalizer_test.encode(test_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_normalizer_train = GaussianNormalizer(train_a_smooth)\n",
    "as_normalizer_test = GaussianNormalizer(test_a_smooth)\n",
    "train_a_smooth = as_normalizer_train.encode(train_a_smooth)\n",
    "test_a_smooth = as_normalizer_test.encode(test_a_smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agx_normalizer_train = GaussianNormalizer(train_a_gradx)\n",
    "agx_normalizer_test = GaussianNormalizer(test_a_gradx)\n",
    "train_a_gradx = agx_normalizer_train.encode(train_a_gradx)\n",
    "test_a_gradx = agx_normalizer_test.encode(test_a_gradx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "agy_normalizer_train = GaussianNormalizer(train_a_grady)\n",
    "agy_normalizer_test = GaussianNormalizer(test_a_grady)\n",
    "train_a_grady = agy_normalizer_train.encode(train_a_grady)\n",
    "test_a_grady = agy_normalizer_test.encode(test_a_grady)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_normalizer_train = GaussianNormalizer(train_u)\n",
    "u_normalizer_test = GaussianNormalizer(test_u)\n",
    "train_u = u_normalizer_train.encode(train_u)\n",
    "test_u = u_normalizer_test.encode(test_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquareMeshGenerator(object):\n",
    "    def __init__(self, real_space, mesh_size):\n",
    "        super(SquareMeshGenerator, self).__init__()\n",
    "        \n",
    "        self.d = len(real_space)\n",
    "        self.s = mesh_size[0]\n",
    "        \n",
    "        assert len(mesh_size) == self.d\n",
    "        \n",
    "        if self.d == 1:\n",
    "            self.n = mesh_size[0]\n",
    "            self.grid = np.linspace(real_space[0][0], real_space[0][1], self.n).reshape((self.n,1))\n",
    "        else:\n",
    "            self.n = 1\n",
    "            grids = []\n",
    "            for j in range(self.d):\n",
    "                grids.append(np.linspace(real_space[j][0], real_space[j][1], mesh_size[j]))\n",
    "                self.n *= mesh_size[j]\n",
    "            self.grid = np.vstack([xx.ravel() for xx in np.meshgrid(*grids)]).T\n",
    "        \n",
    "    def ball_connectivity(self, r):\n",
    "        pwd = sklearn.metrics.pairwise_distances(self.grid)\n",
    "        self.edge_index = np.vstack(np.where(pwd <= r))\n",
    "        self.n_edges = self.edge_index.shape[1]\n",
    "        \n",
    "        return torch.tensor(self.edge_index, dtype=torch.long)\n",
    "    \n",
    "    def get_grid(self):\n",
    "        return torch.tensor(self.grid, dtype=torch.float)\n",
    "    \n",
    "    def attributes(self, f=None, theta=None):\n",
    "        if f is None:\n",
    "            if  theta is None:\n",
    "                edge_attr = self.grid[self.edge_index.T].reshape((self.n_edges,-1))\n",
    "            else:\n",
    "                edge_attr = np.zeros((self.n_edges, 3*self.d))\n",
    "                edge_attr[:,0:2*self.d] = self.grid[self.edge_index.T].reshape((self.n_edges,-1))\n",
    "                edge_attr[:,2*self.d] = theta[self.edge_index[0]]\n",
    "                edge_attr[:,2*self.d+1] = theta[self.edge_index[1]]\n",
    "                \n",
    "        else:\n",
    "            xy = self.grid[self.edge_indx.T].reshape((self.n_edges,-1))\n",
    "            if theta is None:\n",
    "                edge_attr = f(xy[:,0:self.d], xy[:,self.d:])\n",
    "            else:\n",
    "                edge_attr = f(xy[:,0:self.d], xy[:,self.d:], theta[self.edge_index[0]], theta[self.edge_index[1]])\n",
    "                \n",
    "        return torch.tensor(edge_attr, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train grid torch.Size([3721, 2]) edge_index torch.Size([2, 376471]) edge_attr torch.Size([376471, 6])\n"
     ]
    }
   ],
   "source": [
    "radius_train = 0.1\n",
    "s = int(((241 - 1)/r) + 1)\n",
    "meshgenerator_train = SquareMeshGenerator([[0,1],[0,1]],[s,s])\n",
    "edge_index_train = meshgenerator_train.ball_connectivity(radius_train)\n",
    "grid_train = meshgenerator_train.get_grid()\n",
    "data_train = []\n",
    "for j in range(ntrain):\n",
    "    edge_attr_train = meshgenerator_train.attributes(theta=train_a[j,:])\n",
    "    data_train.append(Data(x = torch.cat([grid_train, train_a[j,:].reshape(-1,1), train_a_smooth[j,:].reshape(-1,1), train_a_gradx[j,:].reshape(-1,1)], \n",
    "                                         dim=1),\n",
    "                           y=train_u[j,:], coeff=train_a[j,:], \n",
    "                          edge_index=edge_index_train, edge_attr=edge_attr_train))\n",
    "    \n",
    "print('train grid', grid_train.shape, 'edge_index', edge_index_train.shape, 'edge_attr', edge_attr_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test grid torch.Size([3721, 2]) edge_index torch.Size([2, 376471]) edge_attr torch.Size([376471, 6])\n"
     ]
    }
   ],
   "source": [
    "radius_test = 0.1\n",
    "s = int(((241 - 1)/r) + 1)\n",
    "meshgenerator_test = SquareMeshGenerator([[0,1],[0,1]],[s,s])\n",
    "edge_index_test = meshgenerator_test.ball_connectivity(radius_test)\n",
    "grid_test = meshgenerator_test.get_grid()\n",
    "data_test = []\n",
    "for j in range(ntest):\n",
    "    edge_attr_test = meshgenerator_test.attributes(theta=test_a[j,:])\n",
    "    data_test.append(Data(x = torch.cat([grid_test, test_a[j,:].reshape(-1,1), test_a_smooth[j,:].reshape(-1,1), test_a_gradx[j,:].reshape(-1,1)], \n",
    "                                         dim=1),\n",
    "                           y=test_u[j,:], coeff=test_a[j,:], \n",
    "                          edge_index=edge_index_test, edge_attr=edge_attr_test))\n",
    "    \n",
    "print('test grid', grid_test.shape, 'edge_index', edge_index_test.shape, 'edge_attr', edge_attr_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wangyaohong/.conda/envs/pytorch1.6/lib/python3.7/site-packages/torch_geometric/deprecation.py:13: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "train_loader = DataLoader(data_train, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(data_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing finished, time used: 24.198634035885334\n"
     ]
    }
   ],
   "source": [
    "print('preprocessing finished, time used:', t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(torch.nn.Module):\n",
    "    def __init__(self, layers, nonlinearity, out_nonlinearity=None, normalize=False):\n",
    "        super(DenseNet, self).__init__()\n",
    "        \n",
    "        self.n_layers = len(layers) - 1\n",
    "        \n",
    "        assert self.n_layers >= 1\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        for j in range(self.n_layers):\n",
    "            self.layers.append(nn.Linear(layers[j], layers[j+1]))\n",
    "            \n",
    "            if j != self.n_layers -1:\n",
    "                if normalize:\n",
    "                    self.layers.append(nn.BatchNorm1d(layers[j+1]))\n",
    "                    \n",
    "                self.layers.append(nonlinearity())\n",
    "            \n",
    "        if out_nonlinearity is not None:\n",
    "            self.layers.append(out_nonlinearity())\n",
    "            \n",
    "        def forward(self, x):\n",
    "            for _, l in enumerate(self.layers):\n",
    "                x = l(x)\n",
    "                \n",
    "            return x\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNConv_old(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, nn, aggr='add', root_weight=True, bias=True, **kwargs):\n",
    "        super(NNConv_old, self).__init__(aggr=aggr, **kwargs)\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.nn = nn\n",
    "        self.aggr = aggr\n",
    "        \n",
    "        if root_weight:\n",
    "            self.root = Parameter(torch.Tensor(in_channels, out_channels))\n",
    "        else:\n",
    "            self.register_parameter('root', None)\n",
    "            \n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "            \n",
    "        self.reset_parameters()\n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        reset(self.nn)\n",
    "        size = self.in_channels\n",
    "        random.uniform(size, self.root)\n",
    "        random.uniform(size, self.bias)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = x.unsqueeze(-1) if x.dim() == 1 else x\n",
    "        pseudo = edge_attr.unsqueeze(-1) if edge_attr.dim() == 1 else edge_attr\n",
    "        return self.propagate(edge_index, x=x, pseudo=pseudo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelNN(torch.nn.Module):\n",
    "    def __init__(self, width, ker_width, depth, ker_in, in_width=1, out_width=1):\n",
    "        super(KernelNN, self).__init__()\n",
    "        self.depth = depth\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(in_width, width)\n",
    "        \n",
    "        kernel = DenseNet([ker_in, ker_width, ker_width, width**2], torch.nn.ReLU)\n",
    "        self.conv1 = NNConv_old(width, width, kernel, aggr='mean')\n",
    "        \n",
    "        self.fc2 = torch.nn.Linear(width,1)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr = data.x, data.edge_index, data.edge_attr\n",
    "        x = self.fc1(x)\n",
    "        \n",
    "        for k in range(self.depth):\n",
    "            x = F.relu(self.conv1(x, edge_index, edge_attr))\n",
    "            \n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 64\n",
    "ker_width = 1024\n",
    "depth = 6\n",
    "edge_features = 5\n",
    "node_features = 5\n",
    "model = KernelNN(width,ker_width,depth,edge_features,node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.00001\n",
    "scheduler_step=50\n",
    "scheduler_gamma=0.8\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LpLoss(object):\n",
    "    def __init__(self, d=2, p=2, size_average=True, reduction=True):\n",
    "        super(LpLoss, self).__init__()\n",
    "        \n",
    "        assert d > 0 and p > 0\n",
    "        \n",
    "        self.d = d\n",
    "        self.p = p\n",
    "        self.reduction = reduction\n",
    "        self.size_average = size_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "myloss = LpLoss(size_average=False)\n",
    "u_normalizer_train.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelNN(\n",
       "  (fc1): Linear(in_features=5, out_features=64, bias=True)\n",
       "  (conv1): NNConv_old(\n",
       "    (nn): DenseNet(\n",
       "      (layers): ModuleList(\n",
       "        (0): Linear(in_features=5, out_features=1024, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        (3): ReLU()\n",
       "        (4): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "ttrain = np.zeros((epochs, ))\n",
    "ttest = np.zeros((epochs, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 time: 570.9456669762731 train_mse: 0.88536949634552\n",
      "1 time: 571.1392276976258 train_mse: 0.8798746824264526\n",
      "2 time: 572.4460258558393 train_mse: 0.8745942848920822\n",
      "3 time: 569.2366931512952 train_mse: 0.8697229677438736\n",
      "4 time: 568.9453137014061 train_mse: 0.8653474169969558\n",
      "5 time: 542.2387691037729 train_mse: 0.8611087030172349\n",
      "6 time: 579.5861213244498 train_mse: 0.8572472190856933\n",
      "7 time: 610.3146708263084 train_mse: 0.8534218949079514\n",
      "8 time: 605.5875156987458 train_mse: 0.8501126009225846\n",
      "9 time: 607.4865091769025 train_mse: 0.846898519396782\n",
      "10 time: 610.7819434609264 train_mse: 0.8439859318733215\n",
      "11 time: 608.0910995071754 train_mse: 0.8412635719776154\n",
      "12 time: 611.2883183509111 train_mse: 0.8387409228086472\n",
      "13 time: 615.5026474269107 train_mse: 0.8364101773500443\n",
      "14 time: 607.4928281893954 train_mse: 0.8343162977695465\n",
      "15 time: 606.2502419613302 train_mse: 0.8323686122894287\n",
      "16 time: 604.6898616058752 train_mse: 0.8305724358558655\n",
      "17 time: 547.7946564871818 train_mse: 0.82895987033844\n",
      "18 time: 523.4012223957106 train_mse: 0.8274511951208114\n",
      "19 time: 486.2998034097254 train_mse: 0.8261060917377472\n",
      "20 time: 486.7989322114736 train_mse: 0.8248758083581924\n",
      "21 time: 490.43685158342123 train_mse: 0.8238104957342148\n",
      "22 time: 486.43714862223715 train_mse: 0.8228824812173844\n",
      "23 time: 487.404017646797 train_mse: 0.8219313877820968\n",
      "24 time: 484.99110287893564 train_mse: 0.8211649882793427\n",
      "25 time: 487.81433355715126 train_mse: 0.8203798717260361\n",
      "26 time: 488.6618860187009 train_mse: 0.8197955858707427\n",
      "27 time: 487.7352429740131 train_mse: 0.8192187559604645\n",
      "28 time: 487.5184093955904 train_mse: 0.8186676549911499\n",
      "29 time: 490.0461002672091 train_mse: 0.818251314163208\n",
      "30 time: 486.69837437942624 train_mse: 0.8178410297632217\n",
      "31 time: 486.57786488812417 train_mse: 0.8175507396459579\n",
      "32 time: 486.86891843099147 train_mse: 0.8172677195072174\n",
      "33 time: 486.5481565343216 train_mse: 0.8170180946588517\n",
      "34 time: 483.3260492729023 train_mse: 0.8167942065000534\n",
      "35 time: 483.76543505396694 train_mse: 0.816595396399498\n",
      "36 time: 482.8247124766931 train_mse: 0.816473645567894\n",
      "37 time: 482.4919520225376 train_mse: 0.8163289666175843\n",
      "38 time: 486.0559646496549 train_mse: 0.8161912089586258\n",
      "39 time: 486.73325787950307 train_mse: 0.8160938030481338\n",
      "40 time: 489.3643977623433 train_mse: 0.8160478359460831\n",
      "41 time: 487.55408057849854 train_mse: 0.8159511864185334\n",
      "42 time: 484.57904919423163 train_mse: 0.8159124231338502\n",
      "43 time: 490.84320586919785 train_mse: 0.8159269857406616\n",
      "44 time: 493.6306885033846 train_mse: 0.8157714623212814\n",
      "45 time: 490.78626561164856 train_mse: 0.8157329130172729\n",
      "46 time: 486.2717322325334 train_mse: 0.8156795746088028\n",
      "47 time: 492.3298113876954 train_mse: 0.8156083685159683\n",
      "48 time: 490.00994685385376 train_mse: 0.8155131524801255\n",
      "49 time: 489.65219798870385 train_mse: 0.8155735474824906\n",
      "50 time: 489.3332049837336 train_mse: 0.8155427533388138\n",
      "51 time: 485.8275799257681 train_mse: 0.8154705393314362\n",
      "52 time: 483.70675528235734 train_mse: 0.8153782123327256\n",
      "53 time: 484.7276813806966 train_mse: 0.815351454615593\n",
      "54 time: 487.95429359190166 train_mse: 0.8152806651592255\n",
      "55 time: 489.79896836634725 train_mse: 0.815222464799881\n",
      "56 time: 490.12505423277617 train_mse: 0.8151821011304855\n",
      "57 time: 487.01787773612887 train_mse: 0.8151617407798767\n",
      "58 time: 486.7701981337741 train_mse: 0.8152107131481171\n",
      "59 time: 486.9641561433673 train_mse: 0.815081462264061\n",
      "60 time: 486.6763963634148 train_mse: 0.8149808120727539\n",
      "61 time: 485.0684329988435 train_mse: 0.8149511516094208\n",
      "62 time: 485.1904691429809 train_mse: 0.8148631167411804\n",
      "63 time: 488.4634455284104 train_mse: 0.8148463261127472\n",
      "64 time: 487.7741271490231 train_mse: 0.8147825825214386\n",
      "65 time: 485.13609864842147 train_mse: 0.8146738803386688\n",
      "66 time: 488.4331241864711 train_mse: 0.8145335453748703\n",
      "67 time: 492.03011897485703 train_mse: 0.814513920545578\n",
      "68 time: 489.0639977240935 train_mse: 0.8144671547412873\n",
      "69 time: 487.98021644260734 train_mse: 0.8143431162834167\n",
      "70 time: 490.30737181566656 train_mse: 0.8142579591274262\n",
      "71 time: 488.42676979862154 train_mse: 0.8142020642757416\n",
      "72 time: 486.65721977781504 train_mse: 0.8141279792785645\n",
      "73 time: 487.4618713678792 train_mse: 0.8141054892539978\n",
      "74 time: 488.10824502352625 train_mse: 0.8139647263288498\n",
      "75 time: 489.48316414654255 train_mse: 0.8138609093427658\n",
      "76 time: 484.2361762942746 train_mse: 0.8138248133659363\n",
      "77 time: 486.4354965072125 train_mse: 0.813668886423111\n",
      "78 time: 490.8908534757793 train_mse: 0.8135457569360733\n",
      "79 time: 488.13344835396856 train_mse: 0.8134043741226197\n",
      "80 time: 486.4678982151672 train_mse: 0.8133685803413391\n",
      "81 time: 484.80123701132834 train_mse: 0.8132423466444015\n",
      "82 time: 488.0568177709356 train_mse: 0.8132182830572128\n",
      "83 time: 491.693064362742 train_mse: 0.8130877351760865\n",
      "84 time: 492.0332730477676 train_mse: 0.8130144786834717\n",
      "85 time: 489.9017334189266 train_mse: 0.812817530632019\n",
      "86 time: 486.43019118811935 train_mse: 0.8127177768945694\n",
      "87 time: 487.5959344562143 train_mse: 0.8126005476713181\n",
      "88 time: 486.9324747780338 train_mse: 0.8125364345312118\n",
      "89 time: 491.74956527352333 train_mse: 0.8123218584060669\n",
      "90 time: 487.684725782834 train_mse: 0.8122701686620712\n",
      "91 time: 486.62935771699995 train_mse: 0.812109232544899\n",
      "92 time: 487.7108170995489 train_mse: 0.8121041476726532\n",
      "93 time: 490.9948831005022 train_mse: 0.8119692701101303\n",
      "94 time: 485.4936652574688 train_mse: 0.8119687575101853\n",
      "95 time: 486.4396575232968 train_mse: 0.811781268119812\n",
      "96 time: 489.02209367323667 train_mse: 0.8116044729948044\n",
      "97 time: 491.34198835957795 train_mse: 0.8114278841018677\n",
      "98 time: 491.3281618086621 train_mse: 0.8113629215955734\n",
      "99 time: 489.8414837801829 train_mse: 0.8112517547607422\n",
      "100 time: 491.4436616813764 train_mse: 0.8111438488960266\n",
      "101 time: 536.2360389186069 train_mse: 0.8109802335500718\n",
      "102 time: 532.9581429092214 train_mse: 0.8108913397789002\n",
      "103 time: 533.0529572088271 train_mse: 0.8107774657011032\n",
      "104 time: 533.7238660091534 train_mse: 0.8107065165042877\n",
      "105 time: 530.9484538529068 train_mse: 0.8105849957466126\n",
      "106 time: 529.539685998112 train_mse: 0.8104347640275955\n",
      "107 time: 523.1212935065851 train_mse: 0.8104538130760193\n",
      "108 time: 523.7600376019254 train_mse: 0.8103501653671265\n",
      "109 time: 525.1255784975365 train_mse: 0.8101975244283676\n",
      "110 time: 525.0747819086537 train_mse: 0.8101047277450562\n",
      "111 time: 525.6026284946129 train_mse: 0.8099766266345978\n",
      "112 time: 523.3557497859001 train_mse: 0.8098602992296219\n",
      "113 time: 487.3481773631647 train_mse: 0.8097800529003143\n",
      "114 time: 485.547497282736 train_mse: 0.8096460437774659\n",
      "115 time: 489.97727918997407 train_mse: 0.8095960813760757\n",
      "116 time: 485.49107410013676 train_mse: 0.8095040637254715\n",
      "117 time: 488.097645489499 train_mse: 0.8093300712108612\n",
      "118 time: 490.52639311831445 train_mse: 0.8092653411626816\n",
      "119 time: 489.81190074887127 train_mse: 0.8091555064916611\n",
      "120 time: 489.8754749726504 train_mse: 0.8089993679523468\n",
      "121 time: 488.9828157192096 train_mse: 0.8089511907100677\n",
      "122 time: 485.72362634167075 train_mse: 0.8088495242595672\n",
      "123 time: 487.5064288089052 train_mse: 0.8087682527303696\n",
      "124 time: 488.6656336383894 train_mse: 0.80868947327137\n",
      "125 time: 486.4656425602734 train_mse: 0.8085654157400132\n",
      "126 time: 485.10369868855923 train_mse: 0.8084045630693436\n",
      "127 time: 485.79366350453347 train_mse: 0.8083089816570282\n",
      "128 time: 485.0817884700373 train_mse: 0.8082001101970673\n",
      "129 time: 489.31208731327206 train_mse: 0.8081102353334427\n",
      "130 time: 489.71052301395684 train_mse: 0.807984927892685\n",
      "131 time: 487.0498845819384 train_mse: 0.8078331023454666\n",
      "132 time: 487.6828415058553 train_mse: 0.8078655666112899\n",
      "133 time: 489.5517898192629 train_mse: 0.8076408952474594\n",
      "134 time: 487.8987172562629 train_mse: 0.8076157104969025\n",
      "135 time: 496.98657673504204 train_mse: 0.8074109095335007\n",
      "136 time: 488.40508543048054 train_mse: 0.8074733501672745\n",
      "137 time: 486.4726592609659 train_mse: 0.8073257201910019\n",
      "138 time: 499.75086951442063 train_mse: 0.8071430647373199\n",
      "139 time: 486.92146568372846 train_mse: 0.8070570296049118\n",
      "140 time: 487.2289047418162 train_mse: 0.8068682962656021\n",
      "141 time: 489.4918420733884 train_mse: 0.8068262606859207\n",
      "142 time: 490.40956807881594 train_mse: 0.8066446506977081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143 time: 490.54050638340414 train_mse: 0.8065707820653916\n",
      "144 time: 488.4459029054269 train_mse: 0.8064889991283417\n",
      "145 time: 486.68805147055537 train_mse: 0.8063404870033264\n",
      "146 time: 484.46492191497236 train_mse: 0.8062719571590423\n",
      "147 time: 489.4265095088631 train_mse: 0.8062134033441544\n",
      "148 time: 486.5509097734466 train_mse: 0.8060274970531464\n",
      "149 time: 486.5228855255991 train_mse: 0.8058979469537735\n",
      "150 time: 488.11828797869384 train_mse: 0.8058676946163178\n",
      "151 time: 487.34633979108185 train_mse: 0.8057205021381378\n",
      "152 time: 491.8656376255676 train_mse: 0.8056969559192657\n",
      "153 time: 488.67711600568146 train_mse: 0.8056224399805069\n",
      "154 time: 488.7006934322417 train_mse: 0.8054249799251556\n",
      "155 time: 489.27165769506246 train_mse: 0.8053572922945023\n",
      "156 time: 484.94096324499696 train_mse: 0.8052546662092209\n",
      "157 time: 485.34092209488153 train_mse: 0.8052261704206467\n",
      "158 time: 487.0796016706154 train_mse: 0.8051013106107712\n",
      "159 time: 489.4705542018637 train_mse: 0.8050187629461288\n",
      "160 time: 487.81444044131786 train_mse: 0.8049168980121613\n",
      "161 time: 487.7126889163628 train_mse: 0.804813392162323\n",
      "162 time: 490.191915567033 train_mse: 0.8047312724590302\n",
      "163 time: 491.4567407434806 train_mse: 0.8046137642860413\n",
      "164 time: 491.192672024481 train_mse: 0.8045353877544403\n",
      "165 time: 491.86914972309023 train_mse: 0.8044669824838638\n",
      "166 time: 488.3397336360067 train_mse: 0.8043853610754013\n",
      "167 time: 486.3147993311286 train_mse: 0.8042885184288024\n",
      "168 time: 487.4767547259107 train_mse: 0.8041998767852783\n",
      "169 time: 489.65195442922413 train_mse: 0.80409264087677\n",
      "170 time: 487.5722578726709 train_mse: 0.804027795791626\n",
      "171 time: 490.480090723373 train_mse: 0.803942779302597\n",
      "172 time: 485.80860002711415 train_mse: 0.8038227313756943\n",
      "173 time: 486.5445927651599 train_mse: 0.8037356442213058\n",
      "174 time: 489.7558016879484 train_mse: 0.8036350744962693\n",
      "175 time: 489.51747425086796 train_mse: 0.8035578441619873\n",
      "176 time: 489.8723502410576 train_mse: 0.8034944015741349\n",
      "177 time: 485.75744007341564 train_mse: 0.8033242666721344\n",
      "178 time: 484.9810906769708 train_mse: 0.8032842475175858\n",
      "179 time: 488.3630355456844 train_mse: 0.803161079287529\n",
      "180 time: 490.3656475460157 train_mse: 0.8031061393022537\n",
      "181 time: 491.4095554528758 train_mse: 0.8030159562826157\n",
      "182 time: 489.2588306283578 train_mse: 0.8028903222084045\n",
      "183 time: 487.93381633330137 train_mse: 0.8028052365779876\n",
      "184 time: 489.6250165477395 train_mse: 0.8027386075258255\n",
      "185 time: 491.52666970156133 train_mse: 0.8026191800832748\n",
      "186 time: 489.9014900168404 train_mse: 0.8025597393512726\n",
      "187 time: 487.5079295160249 train_mse: 0.802452198266983\n",
      "188 time: 489.5100532621145 train_mse: 0.8024135136604309\n",
      "189 time: 489.0131854712963 train_mse: 0.8022734314203263\n",
      "190 time: 485.0140750063583 train_mse: 0.802188887000084\n",
      "191 time: 484.9886847678572 train_mse: 0.8021098238229751\n",
      "192 time: 489.2318337066099 train_mse: 0.801993408203125\n",
      "193 time: 487.03555446024984 train_mse: 0.8018444240093231\n",
      "194 time: 487.928941921331 train_mse: 0.8017979454994202\n",
      "195 time: 492.64076927956194 train_mse: 0.8016911447048187\n",
      "196 time: 491.3259876621887 train_mse: 0.8015904158353806\n",
      "197 time: 495.96819230541587 train_mse: 0.8015132510662079\n",
      "198 time: 492.6048665717244 train_mse: 0.8014287239313126\n",
      "199 time: 490.33028673939407 train_mse: 0.8013147395849228\n"
     ]
    }
   ],
   "source": [
    "k = 1\n",
    "for ep in range(epochs):\n",
    "    t1=default_timer()\n",
    "    train_mse = 0.0\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model.forward(batch)\n",
    "        mse = F.mse_loss(out.view(-1,1), batch.y.view(-1,1))\n",
    "        loss = torch.norm(out.view(-1) - batch.y.view(-1),1)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_mse += mse.item()\n",
    "    \n",
    "    scheduler.step()\n",
    "    t2 = default_timer()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    ttrain[ep] = train_mse/(ntrain * k)\n",
    "    \n",
    "    print(ep, 'time:', t2-t1, 'train_mse:', train_mse/len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 77.23782046046108 train_mse: 0.8013147395849228 test: tensor(0.8467)\n"
     ]
    }
   ],
   "source": [
    "batch_size2 = 1\n",
    "t1 = default_timer()\n",
    "test_mse = 0\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        out = model.forward(batch)\n",
    "        test_mse += F.mse_loss(out.view(batch_size2,-1), \n",
    "                          batch.y.view(batch_size2, -1))\n",
    "ttest[ep] = test_mse / ntest\n",
    "t2 = default_timer()\n",
    "print('time:', t2-t1, 'train_mse:', train_mse/len(train_loader), 'test:', test_mse/ntest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"path_train_err.txt\", ttrain)\n",
    "np.savetxt(\"path_test_err.txt\", ttest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.6",
   "language": "python",
   "name": "pytorch1.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
