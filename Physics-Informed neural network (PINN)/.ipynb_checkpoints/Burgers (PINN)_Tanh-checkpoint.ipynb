{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "># Training Burgers equations with PINN\n",
    "-----\n",
    "*Import Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyDOE'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11640/569826654.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpyDOE\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlhs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pyDOE'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.autograd as autograd\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.ticker\n",
    "import numpy as np\n",
    "import time\n",
    "from pyDOE import lhs \n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set default dtype to float32\n",
    "torch.set_default_dtype(torch.float)\n",
    "\n",
    "# Pytorch random number generator\n",
    "torch.manual_seed(1234)\n",
    "\n",
    "# Random number generators in other libraries\n",
    "np.random.seed(1234)\n",
    "\n",
    "#Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets  \n",
    "*****  \n",
    "x, t, usol  \n",
    "*x.shape:(256, 1)  \n",
    "t.shape:(100, 1)  \n",
    "usol.shape:(256, 100)  \n",
    "usol[i][j] = u(x[i],t[j])\n",
    "X.shape:(100, 256)  \n",
    "T.shape:(100, 256)  \n",
    "X: [[-1, -0.99215686,- 0.98431373 ...  0.98431373  0.99215686]; [-1, -0.99215686,- 0.98431373 ...  0.98431373  0.99215686];...]  \n",
    "T: [[0,0,...,0]; [0.01,0.01,...,0.01];...]  \n",
    "x[i] = X[0][i]  \n",
    "t[j] = T[j][0]  \n",
    "usol[i][j] = u(X[0][i],t[j][0])*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11640/627576326.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load data from file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/burgers_datasets.mat'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m't'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0musol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usol'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "#load data from file\n",
    "data = scipy.io.loadmat('Data/burgers_datasets.mat')\n",
    "x = data['x']\n",
    "t = data['t']\n",
    "usol = data['usol']\n",
    "\n",
    "# makes 2 arrays X and T such that u(X[i],T[j])=usol[i][j] are a tuple\n",
    "X, T = np.meshgrid(x, t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*X_u_test:Grid X and T expand  \n",
    "lb, ub: boundary  \n",
    "u_true: expand usol  \n",
    "X_u_test.shape:(25600, 2)  \n",
    "X_u_test:[[-1, -0.99215686,- 0.98431373 ... 0.98431373 0.99215686;-1, -0.99215686,- 0.98431373 ... 0.98431373 0.99215686...];  \n",
    "      [0,0,...,0,0.01,0.01,...,0.01,...]]'  \n",
    "lb:[-1, 0]  \n",
    "ub:[1, 0.99]  \n",
    "u_true.shape:(25600, 1)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11640/2656431540.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_u_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#domain bounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_u_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_u_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "X_u_test = np.hstack((X.flatten()[:,None], T.flatten()[:,None]))\n",
    "\n",
    "#domain bounds\n",
    "lb = X_u_test[0]\n",
    "ub = X_u_test[-1]\n",
    "\n",
    "u_true = usol.flatten('F')[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data\n",
    "*****  \n",
    "*all_X_u_train: Splicing initial conditions and boundary(x, t)  \n",
    "all_u_train: Splicing initial conditions and boundary(u)  \n",
    "idx: choose random N_u points for training  \n",
    "X_u_train: choose indices from set 'idx' (x,t)  \n",
    "u_train: choose indices from set 'idx' (u) (idx point)  \n",
    "X_f_train: joint initial condition boundary condition's (x,t) and points in the grid (initial point)*  \n",
    "*X.shape:(100, 256)  \n",
    "T.shape:(100, 256)  \n",
    "usol.shape:(256, 100)  \n",
    "u(X[0][i],T[j][0])=usol[i][j]  \n",
    "**initial condition:**  \n",
    "u(X[0][i],T[0][0])=usol[i][0]  \n",
    "leftedge_x.shape:(256, 2)  \n",
    "leftedge_u.shape:(256, 1)  \n",
    "**Boundary Condition x=-1:**  \n",
    "u(X[0][0],T[j][0])=usol[0][j] \n",
    "bottomedge_x.shape:(100, 2)  \n",
    "bottomedge_u.shape:(100, 1)  \n",
    "**Boundary Condition x=1:**  \n",
    "u(X[0][-1],T[j][0])=usol[-1][j]  \n",
    "topedge_x.shape:(100, 2)  \n",
    "topedge_u.shape:(100, 1)*\n",
    "  \n",
    "*all_X_u_train.shape:(456, 2)  \n",
    "all_u_train.shape:(456, 1)  \n",
    "idx:N_u*  \n",
    "**X_u_train.shape:(N_u,2)**  \n",
    "**u_train.shape:(N_u,2)**  \n",
    "**X_f_train.shape:(N_f+N_u,2)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingdata(N_u,N_f):\n",
    "    #Initial Condition -1 =< x =< 1 and t=0\n",
    "    leftedge_x = np.hstack((X[0,:][:,None], T[0,:][:,None]))\n",
    "    leftedge_u = usol[:,0][:,None]\n",
    "    \n",
    "    #Boundary Condition x = -1 and 0 =< t =<1\n",
    "    bottomedge_x = np.hstack((X[:,0][:,None], T[:,0][:,None]))\n",
    "    bottomedge_u = usol[0,:][:,None]\n",
    "    \n",
    "    #Boundary Condition x = 1 and 0 =< t =<1\n",
    "    topedge_x = np.hstack((X[:,-1][:,None], T[:,0][:,None]))\n",
    "    topedge_u = usol[-1,:][:,None]\n",
    "    \n",
    "    all_X_u_train = np.vstack([leftedge_x, bottomedge_x, topedge_x])\n",
    "    all_u_train = np.vstack([leftedge_u, bottomedge_u, topedge_u])\n",
    "    \n",
    "    #choose random N_u points for training\n",
    "    idx = np.random.choice(all_X_u_train.shape[0], N_u, replace=False)\n",
    "    \n",
    "    #choose indices from set 'idx' (x,t)\n",
    "    X_u_train = all_X_u_train[idx,:]\n",
    "    u_train = all_u_train[idx,:]\n",
    "    \n",
    "    #Latin Hypercube sampling for collocation points\n",
    "    X_f_train = lb + (ub-lb)*lhs(2,N_f)\n",
    "    X_f_train = np.vstack((X_f_train, X_u_train))\n",
    "    \n",
    "    return X_f_train, X_u_train, u_train\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physics Informed Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequentialmodel(nn.Module):\n",
    "    \n",
    "    def __init__(self,layers):\n",
    "        super().__init__()\n",
    "        \n",
    "        #activation function\n",
    "        self.activation = nn.Tanh()\n",
    "        \n",
    "        #loss function\n",
    "        self.loss_function = nn.MSELoss(reduction = 'mean')\n",
    "        \n",
    "        #Initialise neural network as a list using nn.Modulelist\n",
    "        self.linears = nn.ModuleList([nn.Linear(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.iter = 0\n",
    "        \n",
    "        '''\n",
    "        Simple Linear layers\n",
    "        self.fc1 = nn.linear(2,50)\n",
    "        self.fc2 = nn.linear(50,50)\n",
    "        self.fc3 = nn.linear(50,50)\n",
    "        self.fc4 = nn.linear(50,1)\n",
    "        '''\n",
    "        \n",
    "        for i in range(len(layers)-1):\n",
    "            nn.init.xavier_normal_(self.linears[i].weight.data, gain=1.0)\n",
    "            \n",
    "            # set biases to zero\n",
    "            nn.init.zeros_(self.linears[i].bias.data)\n",
    "    \n",
    "    #forward pass\n",
    "    def forward(self,x):\n",
    "        \n",
    "        if torch.is_tensor(x) != True:\n",
    "            x = torch.from_numpy(x)\n",
    "        \n",
    "        u_b = torch.from_numpy(ub).float().to(device)\n",
    "        l_b = torch.from_numpy(lb).float().to(device)\n",
    "        \n",
    "        #preprocessing input\n",
    "        x = (x - l_b)/(u_b - l_b)\n",
    "        \n",
    "        #convert to float\n",
    "        a = x.float()\n",
    "        \n",
    "        '''\n",
    "        a = self.activation(self.fc1(a))\n",
    "        a = self.activation(self.fc2(a))\n",
    "        a = self.activation(self.fc3(a))\n",
    "        a = self.fc4(a)\n",
    "        '''\n",
    "        \n",
    "        for i in range(len(layers) - 2):\n",
    "            z = self.linears[i](a)\n",
    "            a = self.activation(z)\n",
    "        a = self.linears[-1](a)\n",
    "        return a\n",
    "    \n",
    "    def loss_BC(self,x,y):\n",
    "        \n",
    "        loss_u = self.loss_function(self.forward(x), y)\n",
    "        return loss_u\n",
    "    \n",
    "    def loss_PDE(self, x_to_train_f):\n",
    "        \n",
    "        nu = 0.01/np.pi\n",
    "        x_1_f = x_to_train_f[:,[0]]\n",
    "        x_2_f = x_to_train_f[:,[1]]\n",
    "        \n",
    "        g = x_to_train_f.clone()\n",
    "        \n",
    "        g.requires_grad = True\n",
    "        \n",
    "        u = self.forward(g)\n",
    "        \n",
    "        u_x_t = autograd.grad(u,g,torch.ones([x_to_train_f.shape[0], 1]).to(device), retain_graph=True, create_graph=True)[0]\n",
    "        u_xx_tt = autograd.grad(u_x_t,g,torch.ones(x_to_train_f.shape).to(device), create_graph=True)[0]\n",
    "        \n",
    "        u_x = u_x_t[:,[0]]\n",
    "        \n",
    "        u_t = u_x_t[:,[1]]\n",
    "        \n",
    "        u_xx = u_xx_tt[:,[0]]\n",
    "        \n",
    "        f = u_t + (self.forward(g))*(u_x) - (nu)*u_xx\n",
    "        \n",
    "        loss_f = self.loss_function(f,f_hat)\n",
    "        \n",
    "        return loss_f\n",
    "    \n",
    "    def loss(self, x, y, x_to_train_f):\n",
    "        \n",
    "        loss_u = self.loss_BC(x, y)\n",
    "        loss_f = self.loss_PDE(x_to_train_f)\n",
    "        \n",
    "        loss_val = loss_u + loss_f\n",
    "        \n",
    "        return loss_val\n",
    "    \n",
    "    def closure(self):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = self.loss(X_u_train, u_train, X_f_train)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        self.iter += 1\n",
    "        \n",
    "        if self.iter % 100 == 0:\n",
    "            \n",
    "            error_vec, _ = PINN.test()\n",
    "            \n",
    "            print(loss,error_vec)\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    def test(self):\n",
    "        \n",
    "        u_pred = self.forward(X_u_test_tensor)\n",
    "        \n",
    "        error_vec = torch.linalg.norm((u-u_pred),2)/torch.linalg.norm(u,2) \n",
    "        \n",
    "        u_pred = u_pred.cpu().detach().numpy()\n",
    "        \n",
    "        u_pred = np.reshape(u_pred, (256, 100), order='F')\n",
    "        \n",
    "        return error_vec, u_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solutionplot(u_pred, X_u_train,u_train):\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.axis('off')\n",
    "    \n",
    "    gs0 = gridspec.GridSpec(1, 2)\n",
    "    gs0.update(top=1-0.06, bottom=1-1/3, left=0.15, right=0.85, wspace=0)\n",
    "    ax = plt.subplot(gs0[:, :])\n",
    "    \n",
    "    h = ax.imshow(u_pred, interpolation='nearest', cmap='rainbow', extent=[T.min(), T.max(), X.min(), X.max()], origin='lower',aspect='auto')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    fig.colorvar(h, cax=cax)\n",
    "    \n",
    "    ax.plot(X_u_train[:,1], X_u_train[:,0], 'kx', label='Data (%d points)' % (u_train.shape[0]), makersize = 4, clip_on = False)\n",
    "    \n",
    "    line = np.linsapce(x.min(), x.max(), 2)[:, None]\n",
    "    ax.plot(t[25]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "    ax.plot(t[50]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "    ax.plot(t[75]*np.ones((2,1)), line, 'w-', linewidth = 1)\n",
    "    \n",
    "    ax.set_xlabel('$t$')\n",
    "    ax.set_ylabel('$x$')\n",
    "    ax.legend(frameon=False, loc = 'best')\n",
    "    ax.set_title('$u(x,t)$', fontsize = 10)\n",
    "    \n",
    "    \n",
    "    gs1 = gridspec.GridSpec(1,3)\n",
    "    gs1.update(top=1-1/3, bottom=0, left=0.1, right=0.9, wspace=0.5)\n",
    "    \n",
    "    ax = plt.subplot(gs1[0, 0])\n",
    "    ax.plot(x,usol.T[25,:], 'b-', linewidth = 2, label = 'Exact')\n",
    "    ax.plot(x,u_pred.T[25,:], 'b-', linewidth = 2, label = 'prediction')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$u(x,t)$')\n",
    "    ax.set_title('square')\n",
    "    ax.set_xlim([-1.1,1.1])\n",
    "    ax.set_ylim([-1.1,1.1])\n",
    "    ax.set_title('$t = 0.50s$', fontsize = 10)\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.35), ncol=5, frameon=False)\n",
    "    \n",
    "    ax = plt.subplot(gs1[0, 2])\n",
    "    ax.plot(x,usol.T[75,:], 'b-', linewidth = 2, label = 'Exact')\n",
    "    ax.plot(x,u_pred.T[75,:], 'r-', linewidth = 2, label = 'prediction')\n",
    "    ax.set_xlabel('$x$')\n",
    "    ax.set_ylabel('$u(x,t)$')\n",
    "    ax.axis('square')\n",
    "    ax.set_xlim([-1.1,1.1])\n",
    "    ax.set_ylim([-1.1,1.1])\n",
    "    ax.set_title('$t = 0.75s', fontsize = 10)\n",
    "    \n",
    "    plt.savefig('Burgers.png', dpi = 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_11640/1685540469.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mN_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mN_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_f_train_np_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_u_train_np_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_train_np_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainingdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_u\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#Convert to tensor and send to GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_11640/151435106.py\u001b[0m in \u001b[0;36mtrainingdata\u001b[0;34m(N_u, N_f)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrainingdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_u\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#Initial Condition -1 =< x =< 1 and t=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mleftedge_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mleftedge_u\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0musol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "#Generate Training data\n",
    "\n",
    "#Total number of data points for 'u'\n",
    "N_u = 100\n",
    "N_f = 1000\n",
    "X_f_train_np_array, X_u_train_np_array, u_train_np_array = trainingdata(N_u,N_f)\n",
    "\n",
    "#Convert to tensor and send to GPU\n",
    "X_f_train = torch.from_numpy(X_f_train_np_array).float().to(device)\n",
    "X_u_train = torch.from_numpy(X_u_train_np_array).float().to(device)\n",
    "u_train = torch.from_numpy(u_train_np_array).float().to(device)\n",
    "X_u_test_tensor = torch.from_numpy(X_u_test).float().to(device)\n",
    "u = torch.from_numpy(u_true).float().to(device)\n",
    "f_hat = torch.zeros(X_f_train.shape[0],1).to(device)\n",
    "\n",
    "layers = np.array([2,20,20,20,20,20,20,20,20,1])\n",
    "\n",
    "PINN = Sequentialmodel(layers)\n",
    "\n",
    "PINN.to(device)\n",
    "\n",
    "print(PINN)\n",
    "\n",
    "params = list(PINN.parameters())\n",
    "#Optimizer\n",
    "optimizer = torch.optim.LBFGS(PINN.parameters(), lr=0.1, max_iter=250, max_eval=None, tolerance_grad=1e-05,tolerance_change=1e-05,  \n",
    "                             history_size = 100, line_search_fn = 'strong_wolfe')\n",
    "start_time = time.time()\n",
    "optimizer.step(PINN.closure)\n",
    "\n",
    "elapsed = time.time() - start_time  \n",
    "print('Training time: %.2f' % (elapsed))\n",
    "\n",
    "# Model Accuracy  \n",
    "error_vec, u_pred = PINN.test()\n",
    "\n",
    "print('Test Error: %.5f'  % (error_vec))\n",
    "\n",
    "#Solution Plot \n",
    "solutionplot(u_pred,X_u_train.cpu().detach().numpy(),u_train.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.6",
   "language": "python",
   "name": "pytorch1.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
